{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "594cdcc6-4bfd-4f88-9f1d-c09c4868766a",
   "metadata": {},
   "source": [
    "# Building a phonetic dataset from textgrids and measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e9c29-5dd8-49e8-9e67-eba184299100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parselmouth import Sound\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from phonlab import get_f0\n",
    "from phonlab.utils.phonlablib import tg_to_df, add_context, merge_tiers, explode_intervals, interpolate_measures, loadsig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d05a2-88fe-4142-855d-de55e2b478b9",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb53aee-e9a9-42d4-b3b9-d579a7336ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "au, rate = loadsig('mono.wav')\n",
    "formant = Sound(au, rate).to_formant_burg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0226f-1d29-41e7-b3df-185d0fba2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "phdf, wddf, phptdf = tg_to_df('mono.TextGrid', tiersel=['phone', 'word', 'pointph'])\n",
    "phdf = add_context(phdf, 'phone', nprev=2, nnext=2, ctxcol='phonectx')\n",
    "wddf = add_context(wddf, 'word', nprev=1, nnext=0, ctxcol='wdctx')\n",
    "wdpts = merge_tiers(inner_df=phptdf, outer_df=wddf, suffixes=['_pt', '_wd'], inner_ts=['t1'], drop_repeated_cols='inner')\n",
    "phwddf = merge_tiers(inner_df=phdf, outer_df=wdpts, suffixes=['_ph', ''], outer_ts=['t1_wd', 't2_wd'], drop_repeated_cols='inner_df')\n",
    "vowels = ['ai', 'e', 'a', 'au']\n",
    "vdf = phwddf.query(f'phone in {vowels}')\n",
    "vdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05359f64-3d55-4e36-972c-c208a600da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = explode_intervals(2, ts=['t1_ph', 't2_ph'], df=vdf)\n",
    "vdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4070351-861f-4c5d-9497-ba58ee37ff97",
   "metadata": {},
   "source": [
    "## Generic df interface\n",
    "\n",
    "Establish a pattern for easily getting values from **any** time-based dataframe of measurements.\n",
    "\n",
    "First, create a dataframe of this type as a proof of concept. The `tcol` column has time values, and `genf1` and `genf2` are values for F1 and F2. The `foo` column is added as a nonce column of a non-numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f169a-c177-4063-8286-a7f3b601e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "gendf = pd.read_csv('generic_formant.csv')\n",
    "gendf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce0971-c458-4247-a2c3-f0871e3fa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0df = get_f0(au, fs=rate)\n",
    "f0df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda4c52-a8a4-462d-a1dc-248053451aba",
   "metadata": {},
   "source": [
    "The `vdf` dataframe has metadata for vowels and was already used to get `f1` and `f2` values by using a praat-specific function (`praatformant_to_df`) on a parselmouth Formant object.\n",
    "\n",
    "The `interpolate_measures` function takes a measurement df `measdf` that contains a time column specified by the `meas_ts` parameter. Notice that we take a subset of `gendf` when setting the `measdf` parameter, as non-numeric columns cannot be interpolated and raise an error.\n",
    "\n",
    "The `interpdf` parameter is used to specify the dataframe that has times for which measures from `measdf` are interpolated. The name of the column containing the times to be interpolated is specified by the `interp_ts` parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f72a8-a5f0-4c43-9fca-9108c7acdae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = interpolate_measures(\n",
    "    meas_df=gendf[['tcol', 'f1', 'f2']],  # tcol + cols to interpolate only\n",
    "    meas_ts='tcol',\n",
    "    interp_df=vdf,\n",
    "    interp_ts='obs_t'\n",
    ")\n",
    "vdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fe6bb-b357-43c7-a457-061a014af058",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0df = get_f0(au, fs=rate)\n",
    "vdf = interpolate_measures(\n",
    "    meas_df=f0df.drop(columns='voiced'),  # tcol + cols to interpolate only\n",
    "    meas_ts='sec',\n",
    "    interp_df=vdf,\n",
    "    interp_ts='obs_t', tol=0.1\n",
    ")\n",
    "vdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb375727-532c-4277-a8a6-3ae5db95d2aa",
   "metadata": {},
   "source": [
    "## Applying custom functions to individual tokens\n",
    "\n",
    "Now that we have a dataset of acoustic measures for our vowel tokens, we use the [split-apply-combine pattern](https://pandas.pydata.org/docs/user_guide/groupby.html) to apply custom functions to (1) characterize pitch dynamics; (2) plot the tokens.\n",
    "\n",
    "First, create a token grouper that identifies the individual tokens. In our simple dataset the `t1_ph` column is sufficient. A more complicated dataset would `groupby` multiple columns. The grouper maps `t1_ph` times to the dataframe index, where multiple rows share the same index (in fact, we could also have done `groupby(level=0)` to make an equivalent grouping using the dataframe index instead of the `t1_ph` column). We also restrict the grouper to columns that will be of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6857b-2c10-4887-9d52-20c044ca37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = vdf.groupby(['t1_ph'])[['f0', 'f1', 'f2', 't1_ph', 't2_ph', 'obs_t', 'obs_id']]\n",
    "tokens.groups # maps `t1_ph` times to indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c368aa-376e-4041-a06f-83f4866831d9",
   "metadata": {},
   "source": [
    "### Developing a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e7686-5bbf-4ad5-b9e8-2af14ad7be49",
   "metadata": {},
   "source": [
    "We extract one of these groupings in order to conveniently develop a custom function that operates on a single group at a time. Here we take the group at index `5`, which has `t1_ph` time 0.470892. Our goal is to characterize whether F0 rises or falls over the first and second halves of the token.\n",
    "\n",
    "A subset of the columns from the token is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf01da0-ff26-4cc0-95fc-d91b354a5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vdf.loc[5]\n",
    "x[['t1_ph', 't2_ph', 'f0', 'obs_t', 'obs_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82242dc-769b-4543-8c5f-9d905bb0cd33",
   "metadata": {},
   "source": [
    "Now that we have the group `x` to experiment with, we can work out the steps to categorize tokens by changes in F0 values over time.\n",
    "\n",
    "We start by calling `diff` on the `f0` column, calculates the change of each F0 value from the preceding value. Since there is no value preceding the first one, its `diff` is `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36723925-23d2-4b37-8ddc-1eaf19873499",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['f0'].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4843748-c1ac-4ba3-93f9-f7d7ec363771",
   "metadata": {},
   "source": [
    "Create a slice `[1:]` starting from the second value to skip the `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de96ea-830a-4b81-9c01-7289e53c4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['f0'].diff()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f25d40-364e-4f9a-b6fc-7466739d062d",
   "metadata": {},
   "source": [
    "The `np.where` function is used to label positive rising values as `r` and negative falling values as `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dff177-6b87-4075-87a9-eaa9b0c1c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(x['f0'].diff()[1:] >= 0, 'r', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa536aca-88d0-492a-9c2e-8a8041fdad3b",
   "metadata": {},
   "source": [
    "Finally, we concatenate these labels with the `join` function to create one of four possible F0 contours: `rr`, `rf`, `ff`, `fr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ac3c0-2d62-4167-878b-558da59974a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(np.where(x['f0'].diff()[1:] > 0, 'r', 'f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0428fa-ff4a-4807-89f0-da57b3b6a779",
   "metadata": {},
   "source": [
    "### `apply` an unnamed lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81da13a-ffa2-4328-8ca5-aaa3b86a683f",
   "metadata": {},
   "source": [
    "Since this calculation is simple it's a good candidate for a unnamed lambda function that we can `apply` to each group. The lambda function in combination with `apply` allows us to do the calculation on each group in succession, here named `x`. The result is a `Series` of contour types, indexed by `t1_ph`. `rename` is called on the result to give the `Series` the name `f0type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0bae2-1263-4c4a-9c10-3b51e6b0c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.apply(\n",
    "    lambda x: ''.join(np.where(x['f0'].diff()[1:] > 0, 'r', 'f'))\n",
    ").rename('f0type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9c1fa-6df2-407e-abf4-d0dc87bf90aa",
   "metadata": {},
   "source": [
    "We can `merge` the result back into `vdf` based on the `t1_ph` values. The use of `rename` is important so that the new column has a name. The `merge` would fail without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ea073-c48d-4ac5-81fc-04acec2c126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = vdf.merge(\n",
    "    tokens.apply(\n",
    "        lambda x: ''.join(np.where(x['f0'].diff()[1:] > 0, 'r', 'f'))\n",
    "    ).rename('f0type'),\n",
    "    on='t1_ph'\n",
    ")\n",
    "vdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4592eb2-c52a-4f91-ac2f-5b6526f56506",
   "metadata": {},
   "source": [
    "### `apply` a named function\n",
    "\n",
    "We'll illustrate the use of `apply` with named functions to do the same contour calculation on F1 and F2. We could easily use lambda functions for these as well, but it's good to know how to create named functions. Named functions are especially useful when you want to apply more complicated operations to your dataframe groups than can easily be included in a single line of code. **Always** include a docstring in your function that describes its purpose.\n",
    "\n",
    "The first parameter of the new `risefalltype` function is a dataframe `df`, which will be supplied automatically by `apply`. The second parameter names the column in `df` to be summarized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0789814-c0df-4305-b77d-3ba9bc1f8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risefalltype(df, col):\n",
    "    '''\n",
    "    Return a joined string of 'r' and 'f' for each interval in a dataframe\n",
    "    (pairs of successive rows) where the values of `col` are rising\n",
    "    ('r') or falling ('f'). The number of 'r' and 'f' characters in the\n",
    "    result is one less than the number of rows.\n",
    "    '''\n",
    "    return ''.join(np.where(df[col].diff()[1:] > 0, 'r', 'f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba357428-a8d4-4363-b352-4ebed456941a",
   "metadata": {},
   "source": [
    "Summarize F1 and F2 using the named function and `merge` with `vdf`. The first parameter to `apply` names the function to use (note that it is the function's symbol, like a variable name, not a string!). `apply` passes each dataframe group to the function as the first parameter. Named parameters like `col` are also passed to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6c1f7-81fd-4068-a7ac-931e203afe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = vdf.merge(\n",
    "    tokens.apply(risefalltype, col='f1').rename('f1type'),\n",
    "    on='t1_ph'\n",
    ")\n",
    "vdf = vdf.merge(\n",
    "    tokens.apply(risefalltype, col='f2').rename('f2type'),\n",
    "    on='t1_ph'\n",
    ")\n",
    "vdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18ec2f-e6ad-4add-a8b2-432f197f6004",
   "metadata": {},
   "source": [
    "## Plot by groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0dd13-2ed6-4c05-ac69-24808c1c47f8",
   "metadata": {},
   "source": [
    "F0, F1, and F2 plots showing all measures and interpolated values at 0%, 50%, 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa80bc-e1c9-4c1c-9cdd-5e1231faff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 1, figsize=[6, 8])\n",
    "for i, (t1, g) in enumerate(tokens):\n",
    "    t1 = g['t1_ph'].iloc[0]\n",
    "    t2 = g['t2_ph'].iloc[0]\n",
    "    for col in ('f0', 'f1', 'f2'):\n",
    "        if col == 'f0':\n",
    "            mdf = f0df.query(f'(sec >= {t1}) and (sec <= {t2})')\n",
    "            tcol = 'sec'\n",
    "        else:\n",
    "            mdf = gendf.query(f'(tcol >= {t1}) and (tcol <= {t2})')\n",
    "            tcol = 'tcol'\n",
    "        axes[i].plot(mdf[tcol], mdf[col])\n",
    "        axes[i].scatter(mdf[tcol], mdf[col])\n",
    "        axes[i].scatter(g['obs_t'], g[col])\n",
    "        axes[i].set_xlim([t1-0.010, t2+0.010])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
